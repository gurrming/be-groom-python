import pandas as pd
import torch
from sqlalchemy import create_engine, text
from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer
from langdetect import detect, DetectorFactory
from tqdm import tqdm
import sys

# ì–¸ì–´ ê°ì§€ ëœë¤ ì‹œë“œ ê³ ì • (ì¼ê´€ì„± ìœ ì§€)
DetectorFactory.seed = 0

# ==========================================
# 1. DB ì„¤ì • (ë³¸ì¸ ì„¤ì •ì— ë§ê²Œ ìˆ˜ì •)
# ==========================================
DB_USER = "postgres"      
DB_PASSWORD = "0000"  
DB_HOST = "localhost"          
DB_PORT = "15432"               
DB_NAME = "app"       

db_url = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
try:
    engine = create_engine(db_url)
    connection = engine.connect()
    print("âœ… DB ì—°ê²° ì„±ê³µ!")
except Exception as e:
    print(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
    sys.exit(1)

# ==========================================
# 2. ë§¥ë¶(MPS) ê°€ì† ì¥ì¹˜ ì„¤ì •
# ==========================================
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("ğŸ Apple Silicon(M1/M2/M3) GPU ê°€ì†(MPS)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
elif torch.cuda.is_available():
    device = torch.device("cuda")
    print("ğŸš€ NVIDIA GPU(CUDA)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
else:
    device = torch.device("cpu")
    print("ğŸ¢ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# ==========================================
# 3. ë‰´ìŠ¤ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
# ==========================================
def analyze_news_incremental():
    table_name = "news_data"
    id_column = "news_id"
    model_name = "ProsusAI/finbert"
    
    print(f"\n======== [{table_name}] ì‹ ê·œ ë°ì´í„° ë¶„ì„ ì‹œì‘ (FinBERT) ========")

    # 1. ë¯¸ì²˜ë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    query = f"""
    SELECT {id_column}, title, COALESCE(description, '') as description
    FROM {table_name}
    WHERE sentiment_score IS NULL
    ORDER BY {id_column} DESC;
    """
    
    with engine.connect() as conn:
        df = pd.read_sql(query, conn)
    
    total_rows = len(df)
    if total_rows == 0:
        print("   ğŸ‰ ë‰´ìŠ¤ ë°ì´í„°ëŠ” ëª¨ë‘ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ‘‰ ë¶„ì„ ëŒ€ìƒ(ë‰´ìŠ¤): {total_rows}ê°œ")

    # 2. ëª¨ë¸ ë¡œë“œ
    try:
        model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        classifier = pipeline("text-classification", model=model, tokenizer=tokenizer, device=device, truncation=True, max_length=512)
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 3. ë°ì´í„° ì „ì²˜ë¦¬
    df['full_text'] = df.apply(lambda row: f"{row['title']} {row['description']}".strip(), axis=1)
    updates = []

    # 4. ë°°ì¹˜ ë¶„ì„
    for i in tqdm(range(0, total_rows, 32), desc="Processing News"):
        batch_df = df.iloc[i : i + 32]
        texts = batch_df['full_text'].tolist()
        ids = batch_df[id_column].tolist()
        
        try:
            results = classifier(texts)
        except Exception as e:
            continue
        
        for doc_id, res in zip(ids, results):
            updates.append({
                "id": int(doc_id),
                "score": float(res['score']),
                "label": str(res['label']) # positive, negative, neutral
            })

    # 5. DB ì—…ë°ì´íŠ¸
    if updates:
        print(f"ğŸ’¾ {len(updates)}ê±´ ë‰´ìŠ¤ ë°ì´í„° ì €ì¥ ì¤‘...")
        update_query = text(f"""
            UPDATE {table_name}
            SET sentiment_score = :score,
                sentiment_label = :label
            WHERE {id_column} = :id
        """)
        with engine.begin() as conn:
            conn.execute(update_query, updates)
        print("âœ… ë‰´ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")

# ==========================================
# 4. ì»¤ë®¤ë‹ˆí‹° ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ (Hybrid: KR/EN)
# ==========================================
def analyze_community_hybrid_incremental():
    table_name = "community_data"
    id_column = "community_id"
    
    print(f"\n======== [{table_name}] ì‹ ê·œ ë°ì´í„° í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹œì‘ (KR/EN) ========")

    # 1. ë¯¸ì²˜ë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    query = f"""
    SELECT {id_column}, title, COALESCE(description, '') as description
    FROM {table_name}
    WHERE sentiment_score IS NULL
    ORDER BY {id_column} DESC;
    """
    
    with engine.connect() as conn:
        df = pd.read_sql(query, conn)
    
    total_rows = len(df)
    if total_rows == 0:
        print("   ğŸ‰ ì»¤ë®¤ë‹ˆí‹° ë°ì´í„°ëŠ” ëª¨ë‘ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ‘‰ ë¶„ì„ ëŒ€ìƒ(ì»¤ë®¤ë‹ˆí‹°): {total_rows}ê°œ (í•œêµ­ì–´/ì˜ì–´ ìë™ ë¶„ë¥˜)")

    # 2. ëª¨ë¸ 2ê°œ ë¡œë“œ (í•œêµ­ì–´ & ì˜ì–´)
    print("â³ ëª¨ë¸ ë¡œë”© ì¤‘... (KR-FinBert & CryptoBERT)")
    try:
        # í•œêµ­ì–´ ëª¨ë¸
        pipe_ko = pipeline("text-classification", model="snunlp/KR-FinBert-SC", device=device, truncation=True, max_length=512)
        # ì˜ì–´ ëª¨ë¸
        pipe_en = pipeline("text-classification", model="ElKulako/cryptobert", device=device, truncation=True, max_length=512)
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    df['full_text'] = df.apply(lambda row: f"{row['title']} {row['description']}".strip(), axis=1)
    updates = []

    print("ğŸŒŠ ì–¸ì–´ ê°ì§€ ë° ì •ë°€ ë¶„ì„ ì‹¤í–‰ ì¤‘...")

    # 3. ê°œë³„ ë°ì´í„° ì²˜ë¦¬ (ì–¸ì–´ ê°ì§€ ë•Œë¬¸ì— ë°˜ë³µë¬¸ ì‚¬ìš©)
    for i, row in tqdm(df.iterrows(), total=total_rows, desc="Processing Community"):
        text_content = row['full_text']
        doc_id = row[id_column]
        
        if not text_content: continue

        # A. ì–¸ì–´ ê°ì§€
        try:
            lang = detect(text_content) # ko, en ë“±
        except:
            lang = 'en' # ì‹¤íŒ¨ ì‹œ ì˜ì–´ ëª¨ë¸(ì´ëª¨ì§€ ë“±) ì‚¬ìš©

        # B. ëª¨ë¸ ì„ íƒ ë° ë¼ë²¨ í†µì¼
        try:
            if lang == 'ko':
                # [í•œêµ­ì–´] KR-FinBert
                res = pipe_ko(text_content)[0]
                label = res['label'] # neutral, positive, negative
                score = res['score']
            else:
                # [ì˜ì–´] CryptoBERT
                res = pipe_en(text_content)[0]
                raw_label = res['label'] # Neutral, Bullish, Bearish
                score = res['score']
                
                # ë¼ë²¨ í†µì¼ (DB ì €ì¥ìš©)
                if raw_label == 'Bullish': label = 'positive'
                elif raw_label == 'Bearish': label = 'negative'
                else: label = 'neutral'
        except:
            continue

        updates.append({
            "id": int(doc_id),
            "score": float(score),
            "label": str(label)
        })

    # 4. DB ì—…ë°ì´íŠ¸
    if updates:
        print(f"ğŸ’¾ {len(updates)}ê±´ ì»¤ë®¤ë‹ˆí‹° ë°ì´í„° ì €ì¥ ì¤‘...")
        update_query = text(f"""
            UPDATE {table_name}
            SET sentiment_score = :score,
                sentiment_label = :label
            WHERE {id_column} = :id
        """)
        with engine.begin() as conn:
            conn.execute(update_query, updates)
        print("âœ… ì»¤ë®¤ë‹ˆí‹° ì—…ë°ì´íŠ¸ ì™„ë£Œ!")

# ==========================================
# 5. ì‹¤í–‰ (ë‰´ìŠ¤ -> ì»¤ë®¤ë‹ˆí‹° ìˆœì„œ)
# ==========================================
if __name__ == "__main__":
    # 1. ë‰´ìŠ¤ ë°ì´í„° ì²˜ë¦¬
    analyze_news_incremental()
    
    # 2. ì»¤ë®¤ë‹ˆí‹° ë°ì´í„° ì²˜ë¦¬ (Hybrid)
    analyze_community_hybrid_incremental()
    
    print("\nğŸ‰ ëª¨ë“  ì‹ ê·œ ë°ì´í„° ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    connection.close()
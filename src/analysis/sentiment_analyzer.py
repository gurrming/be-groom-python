import pandas as pd
import torch
from sqlalchemy import create_engine, text
from transformers import pipeline
from tqdm import tqdm
import sys
import re
import schedule
import time
from datetime import datetime
from qdrant_client import QdrantClient

# ==========================================
# 1. ì„¤ì • ë° DB ì—°ê²° (Global)
# ==========================================
DB_USER = "postgres"      
DB_PASSWORD = "0000"  
DB_HOST = "localhost"          
DB_PORT = "15432"               
DB_NAME = "app"       

db_url = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# ì—”ì§„ì€ ì „ì—­ìœ¼ë¡œ í•œ ë²ˆë§Œ ìƒì„± (ë§¤ë²ˆ ì—°ê²°í•˜ë©´ ë¶€í•˜ ë°œìƒ)
try:
    engine = create_engine(db_url)
    print("âœ… [Init] DB ì—°ê²° ì„±ê³µ!")
except Exception as e:
    print(f"âŒ [Init] DB ì—°ê²° ì‹¤íŒ¨: {e}")
    sys.exit(1)

qdrant = QdrantClient(url="http://localhost:6333")
print("âœ… [Init] Qdrant ì—°ê²° ì„±ê³µ!")

# MPS(Mac) / CUDA / CPU ì„¤ì •
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("ğŸ Apple MPS ê°€ì†ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
elif torch.cuda.is_available():
    device = torch.device("cuda")
    print("ğŸš€ NVIDIA GPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
else:
    device = torch.device("cpu")
    print("ğŸ¢ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# ==========================================
# 2. ì‚¬ì „ ë° ê·œì¹™ ì •ì˜
# ==========================================
SLANG_DICT = {
    "ë–¡ë½": " HUGE CRASH ", "í­ë½": " PLUMMET ", "ë‚˜ë½": " HELL DUMP ",
    "í•œê°•": " SUICIDE DEPRESSION ", "ë”í™©ì± ": " RUN AWAY ", "ë”í™©ì°¨": " RUN AWAY ",
    "íƒˆì¶œ": " ESCAPE ", "ì†ì ˆ": " PANIC SELL ", "ì„¤ê±°ì§€": " SCAM DUMP ",
    "í‘ìš°": " VICTIM ", "ë¬¼ë ¸": " TRAPPED LOSS ", "ìƒí": " DELISTING ",
    "ìŠ¤ìº ": " SCAM ", "ë§í–ˆ": " RUINED ", "ë¬´ì„­ë‹¤": " FEAR ", "ê³µí¬": " FEAR ",
    "ë–¨ë¦°ë‹¤": " FEAR ", "drained": " HACKED ", "í„¸ë ¸ë‹¤": " HACKED ", "í•´í‚¹": " HACKED ",
    "ë–¡ìƒ": " HUGE PUMP ", "ë¶ˆì¥": " BULL MARKET ", "íˆ¬ë”ë¬¸": " MOONING ",
    "ê°€ì¦ˆì•„": " TO THE MOON ", "ì¡´ë²„": " HODL ", "í™€ë”©": " HODL ",
    "ì¡¸ì—…": " RETIRE RICH ", "ìµì ˆ": " TAKE PROFIT ", "ë°˜ë“±": " REBOUND ",
    "ë§ì•„ì˜¬ë ¤": " PUMP UP ", "í’€ë§¤ìˆ˜": " ALL IN BUY ", "ì˜ëŒ": " ALL IN BUY ",
    "ë¡±": " LONG POSITION "
}

HARD_RULES = {
    "negative": [
        "ìƒì¥íì§€", "ìƒí", "í•´í‚¹ë‹¹í•¨", "í•´í‚¹ ë‹¹í•¨", "drained", "hacked", 
        "rug pull", "ëŸ¬ê·¸í’€", "ì¶œê¸ˆ ì¤‘ë‹¨", "ì…ì¶œê¸ˆ ì¤‘ë‹¨", "êµ¬ì†", "ì²´í¬"
    ],
    "positive": []
}

# ==========================================
# 3. ëª¨ë¸ ë¡œë“œ (ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰)
# ==========================================
print("â³ ëª¨ë¸ ë¡œë”© ì¤‘... (ì´ ê³¼ì •ì€ í•œ ë²ˆë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤)")
pipe_news = pipeline("text-classification", model="ProsusAI/finbert", device=device, truncation=True, max_length=512)
pipe_trans = pipeline("translation", model="Helsinki-NLP/opus-mt-ko-en", device=device, truncation=True, max_length=512)
pipe_crypto = pipeline("text-classification", model="ElKulako/cryptobert", device=device, truncation=True, max_length=512)
print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# ==========================================
# 4. í—¬í¼ í•¨ìˆ˜
# ==========================================
def apply_hard_rules(text):
    for kw in HARD_RULES["negative"]:
        if kw in text: return 0.99, "negative"
    for kw in HARD_RULES["positive"]:
        if kw in text: return 0.99, "positive"
    return None, None

def inject_slang(text):
    for slang, eng in SLANG_DICT.items():
        if slang in text: text = text.replace(slang, eng)
    return text

def has_korean(text):
    return bool(re.search("[ê°€-í£]", text))

def save_to_db(table, id_col, data):
    if not data: return
    print(f"   ğŸ’¾ {len(data)}ê±´ [{table}] ì ìˆ˜ ì €ì¥ ì¤‘...")
    
    # íŠ¸ëœì­ì…˜ì„ ì§§ê²Œ ê°€ì ¸ê°€ê¸° ìœ„í•´ ê°œë³„ ì—…ë°ì´íŠ¸ í˜¹ì€ ì‘ì€ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    try:
        with engine.connect() as conn: # begin() ëŒ€ì‹  connect() ì‚¬ìš©
            for item in data:
                query = text(f"""
                    UPDATE {table}
                    SET sentiment_score = :score, sentiment_label = :label
                    WHERE {id_col} = :id
                """)
                conn.execute(query, {"score": item["score"], "label": item["label"], "id": item["id"]})
                
                # Qdrant ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
                collection_name = "news_collection" if "news" in table else "community_collection"
                qdrant.set_payload(
                    collection_name=collection_name,
                    payload={"sentiment": item["score"]},
                    points=[item["id"]]
                )
            conn.commit() # ë§ˆì§€ë§‰ì— í•œ ë²ˆì— ì»¤ë°‹
        print("   âœ… Postgres & Qdrant ì ìˆ˜ ë™ê¸°í™” ì™„ë£Œ!")
    except Exception as e:
        print(f"   âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        
# ==========================================
# 5. ë©”ì¸ ë¶„ì„ í•¨ìˆ˜
# ==========================================
def analyze_news():
    query = """
    SELECT news_id, title, COALESCE(description, '') as description
    FROM news_data
    WHERE sentiment_score IS NULL
    ORDER BY news_id DESC;
    """
    with engine.connect() as conn:
        df = pd.read_sql(query, conn)
    
    if len(df) == 0:
        return # ì¡°ìš©íˆ ë¦¬í„´

    print(f"\nğŸ“° [NEWS] {len(df)}ê±´ ì‹ ê·œ ë¶„ì„ ì‹œì‘...")
    df['full_text'] = df.apply(lambda row: f"{row['title']} {row['description']}".strip(), axis=1)
    
    updates = []
    batch_size = 32

    for i in range(0, len(df), batch_size):
        batch = df.iloc[i : i + batch_size]
        texts = batch['full_text'].tolist()
        ids = batch['news_id'].tolist()
        
        try:
            results = pipe_news(texts)
            for doc_id, res in zip(ids, results):
                updates.append({
                    "id": int(doc_id),
                    "score": float(res['score']),
                    "label": str(res['label'])
                })
        except Exception as e:
            print(f"   âš ï¸ ë°°ì¹˜ ì²˜ë¦¬ ì—ëŸ¬: {e}")
            continue

    if updates:
        save_to_db("news_data", "news_id", updates)

def analyze_community():
    query = """
    SELECT community_id, title, COALESCE(description, '') as description
    FROM community_data
    WHERE sentiment_score IS NULL
    ORDER BY community_id DESC;
    """
    with engine.connect() as conn:
        df = pd.read_sql(query, conn)
    
    if len(df) == 0:
        return

    print(f"\nğŸ‘½ [COMMUNITY] {len(df)}ê±´ ì‹ ê·œ ë¶„ì„ ì‹œì‘...")
    df['full_text'] = df.apply(lambda row: f"{row['title']} {row['description']}".strip(), axis=1)
    
    updates = []
    
    for idx, row in tqdm(df.iterrows(), total=len(df), desc="Processing"):
        doc_id = row['community_id']
        text_content = row['full_text']
        if not text_content: continue

        # 1. Hard Rule
        hr_score, hr_label = apply_hard_rules(text_content)
        if hr_label:
            updates.append({"id": doc_id, "score": hr_score, "label": hr_label})
            continue

        # 2. Slang Injection
        text_content = inject_slang(text_content)

        # 3. Translation
        final_text = text_content
        if has_korean(text_content):
            try:
                trans_res = pipe_trans(text_content[:512])
                final_text = trans_res[0]['translation_text']
            except: pass

        # 4. AI Analysis
        try:
            res = pipe_crypto(final_text[:512])[0]
            raw_label = res['label']
            if raw_label == 'Bullish': label = 'positive'
            elif raw_label == 'Bearish': label = 'negative'
            else: label = 'neutral'
            
            updates.append({
                "id": int(doc_id),
                "score": float(res['score']),
                "label": label
            })
        except: continue

    if updates:
        save_to_db("community_data", "community_id", updates)

# ==========================================
# 6. ìŠ¤ì¼€ì¤„ëŸ¬ Job ë° ì‹¤í–‰
# ==========================================
def job():
    print(f"\n[ğŸ”„ ë¶„ì„ ì‚¬ì´í´ ì‹œì‘] {datetime.now().strftime('%H:%M:%S')}")
    try:
        analyze_news()
        analyze_community()
        print(f"[âœ… ì‚¬ì´í´ ì¢…ë£Œ] ëŒ€ê¸° ëª¨ë“œë¡œ ì „í™˜...")
    except Exception as e:
        print(f"[âŒ ì‚¬ì´í´ ì—ëŸ¬] {e}")

if __name__ == "__main__":
    print("ğŸš€ ê°ì„± ë¶„ì„ ì—ì´ì „íŠ¸ ê°€ë™ (10ë¶„ ì£¼ê¸°)")
    print("   -> ë©”ëª¨ë¦¬ì— ëª¨ë¸ ì ì¬ ì™„ë£Œ. ëŒ€ê¸° ì¤‘...")
    
    # 1. ì‹¤í–‰ ì¦‰ì‹œ í•œ ë²ˆ ì²˜ë¦¬
    job()
    
    # 2. 10ë¶„ë§ˆë‹¤ ë°˜ë³µ ìŠ¤ì¼€ì¤„ë§
    schedule.every(30).minutes.do(job)
    
    while True:
        schedule.run_pending()
        time.sleep(1)